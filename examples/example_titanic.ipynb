{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\victorhu.contrera\\Anaconda3\\envs\\prodexire\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "base_path = Path.cwd().parent\n",
    "data_dir = os.path.join(base_path, 'data', 'titanic.csv')\n",
    "data = pd.read_csv(data_dir, index_col=0)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select important features \n",
    "selected_columns = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "selected_data = data[selected_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age has 177 missing values\n",
      "Embarked has 2 missing values\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "def check_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        missing_values = df[col].isnull().sum()\n",
    "        if missing_values > 0:\n",
    "            print(f'{col} has {missing_values} missing values')\n",
    "            \n",
    "check_missing_values(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "selected_data[['Age', 'Fare']] = imputer.fit_transform(selected_data[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_features = ['Sex', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables and prepare data for training\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('onehot', OneHotEncoder(sparse_output=False), categorical_features),\n",
    "        ('scaler', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = preprocessor.fit_transform(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['onehot__Sex_female', 'onehot__Sex_male', 'onehot__Embarked_C',\n",
       "       'onehot__Embarked_Q', 'onehot__Embarked_S', 'onehot__Embarked_nan',\n",
       "       'scaler__Pclass', 'scaler__Age', 'scaler__SibSp', 'scaler__Parch',\n",
       "       'scaler__Fare', 'remainder__Survived'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepared_data[:, :-1]\n",
    "y = prepared_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val split \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\victorhu.contrera\\Anaconda3\\envs\\prodexire\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a train model \n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(8, activation='linear', input_shape=(X_train.shape[1],)),\n",
    "                                    tf.keras.layers.Dropout(0.2),\n",
    "                                    tf.keras.layers.Dense(4, activation='relu'),\n",
    "                                    tf.keras.layers.Dropout(0.1),\n",
    "                                    tf.keras.layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\victorhu.contrera\\Anaconda3\\envs\\prodexire\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\victorhu.contrera\\Anaconda3\\envs\\prodexire\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\victorhu.contrera\\Anaconda3\\envs\\prodexire\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 0.7607 - accuracy: 0.4359 - val_loss: 0.7260 - val_accuracy: 0.4406\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7286 - accuracy: 0.4956 - val_loss: 0.6991 - val_accuracy: 0.4825\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7248 - accuracy: 0.5114 - val_loss: 0.6819 - val_accuracy: 0.5594\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.5589 - val_loss: 0.6692 - val_accuracy: 0.5874\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5589 - val_loss: 0.6575 - val_accuracy: 0.6224\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.6362 - val_loss: 0.6446 - val_accuracy: 0.6923\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6520 - val_loss: 0.6302 - val_accuracy: 0.7203\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6731 - val_loss: 0.6177 - val_accuracy: 0.7483\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6784 - val_loss: 0.6058 - val_accuracy: 0.7483\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.7206 - val_loss: 0.5917 - val_accuracy: 0.7413\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6960 - val_loss: 0.5786 - val_accuracy: 0.7483\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7118 - val_loss: 0.5667 - val_accuracy: 0.7552\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7258 - val_loss: 0.5552 - val_accuracy: 0.7552\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7381 - val_loss: 0.5469 - val_accuracy: 0.7552\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7452 - val_loss: 0.5364 - val_accuracy: 0.7762\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7381 - val_loss: 0.5252 - val_accuracy: 0.7762\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7557 - val_loss: 0.5170 - val_accuracy: 0.7902\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7434 - val_loss: 0.5070 - val_accuracy: 0.7832\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7750 - val_loss: 0.4982 - val_accuracy: 0.7762\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7715 - val_loss: 0.4901 - val_accuracy: 0.7762\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7540 - val_loss: 0.4835 - val_accuracy: 0.7762\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7698 - val_loss: 0.4768 - val_accuracy: 0.7832\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7592 - val_loss: 0.4712 - val_accuracy: 0.7972\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7575 - val_loss: 0.4664 - val_accuracy: 0.8042\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7750 - val_loss: 0.4623 - val_accuracy: 0.8042\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7803 - val_loss: 0.4590 - val_accuracy: 0.8182\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7838 - val_loss: 0.4560 - val_accuracy: 0.8252\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7698 - val_loss: 0.4523 - val_accuracy: 0.8252\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7575 - val_loss: 0.4503 - val_accuracy: 0.8252\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7733 - val_loss: 0.4488 - val_accuracy: 0.8322\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7434 - val_loss: 0.4475 - val_accuracy: 0.8252\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7856 - val_loss: 0.4453 - val_accuracy: 0.8322\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7979 - val_loss: 0.4426 - val_accuracy: 0.8322\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7856 - val_loss: 0.4397 - val_accuracy: 0.8322\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7698 - val_loss: 0.4384 - val_accuracy: 0.8252\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7803 - val_loss: 0.4380 - val_accuracy: 0.8322\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7873 - val_loss: 0.4355 - val_accuracy: 0.8252\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7663 - val_loss: 0.4338 - val_accuracy: 0.8392\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7838 - val_loss: 0.4328 - val_accuracy: 0.8392\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7873 - val_loss: 0.4321 - val_accuracy: 0.8392\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7645 - val_loss: 0.4316 - val_accuracy: 0.8392\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.8067 - val_loss: 0.4309 - val_accuracy: 0.8322\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7979 - val_loss: 0.4293 - val_accuracy: 0.8322\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7873 - val_loss: 0.4277 - val_accuracy: 0.8392\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7926 - val_loss: 0.4260 - val_accuracy: 0.8462\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7856 - val_loss: 0.4250 - val_accuracy: 0.8462\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7909 - val_loss: 0.4251 - val_accuracy: 0.8462\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7786 - val_loss: 0.4239 - val_accuracy: 0.8392\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7961 - val_loss: 0.4237 - val_accuracy: 0.8462\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7803 - val_loss: 0.4232 - val_accuracy: 0.8462\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7750 - val_loss: 0.4229 - val_accuracy: 0.8392\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7909 - val_loss: 0.4225 - val_accuracy: 0.8322\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7821 - val_loss: 0.4217 - val_accuracy: 0.8322\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7961 - val_loss: 0.4207 - val_accuracy: 0.8392\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7891 - val_loss: 0.4196 - val_accuracy: 0.8392\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7891 - val_loss: 0.4194 - val_accuracy: 0.8392\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7909 - val_loss: 0.4193 - val_accuracy: 0.8392\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7926 - val_loss: 0.4184 - val_accuracy: 0.8392\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7821 - val_loss: 0.4181 - val_accuracy: 0.8322\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7979 - val_loss: 0.4175 - val_accuracy: 0.8322\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7909 - val_loss: 0.4173 - val_accuracy: 0.8322\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7926 - val_loss: 0.4166 - val_accuracy: 0.8322\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8014 - val_loss: 0.4157 - val_accuracy: 0.8392\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8102 - val_loss: 0.4151 - val_accuracy: 0.8392\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.8049 - val_loss: 0.4144 - val_accuracy: 0.8322\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7944 - val_loss: 0.4138 - val_accuracy: 0.8322\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7856 - val_loss: 0.4135 - val_accuracy: 0.8322\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7733 - val_loss: 0.4134 - val_accuracy: 0.8322\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8084 - val_loss: 0.4134 - val_accuracy: 0.8322\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7768 - val_loss: 0.4128 - val_accuracy: 0.8322\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7891 - val_loss: 0.4128 - val_accuracy: 0.8322\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7944 - val_loss: 0.4122 - val_accuracy: 0.8322\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8190 - val_loss: 0.4119 - val_accuracy: 0.8322\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7873 - val_loss: 0.4116 - val_accuracy: 0.8322\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7926 - val_loss: 0.4116 - val_accuracy: 0.8322\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8032 - val_loss: 0.4107 - val_accuracy: 0.8322\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8014 - val_loss: 0.4114 - val_accuracy: 0.8322\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7733 - val_loss: 0.4119 - val_accuracy: 0.8322\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7944 - val_loss: 0.4112 - val_accuracy: 0.8252\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7944 - val_loss: 0.4103 - val_accuracy: 0.8252\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7944 - val_loss: 0.4100 - val_accuracy: 0.8322\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7961 - val_loss: 0.4101 - val_accuracy: 0.8252\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8032 - val_loss: 0.4100 - val_accuracy: 0.8252\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7979 - val_loss: 0.4096 - val_accuracy: 0.8252\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8155 - val_loss: 0.4093 - val_accuracy: 0.8252\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7961 - val_loss: 0.4093 - val_accuracy: 0.8322\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7944 - val_loss: 0.4085 - val_accuracy: 0.8182\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8049 - val_loss: 0.4086 - val_accuracy: 0.8252\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7768 - val_loss: 0.4086 - val_accuracy: 0.8252\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7926 - val_loss: 0.4083 - val_accuracy: 0.8252\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8049 - val_loss: 0.4081 - val_accuracy: 0.8252\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7768 - val_loss: 0.4082 - val_accuracy: 0.8252\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7873 - val_loss: 0.4078 - val_accuracy: 0.8252\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7926 - val_loss: 0.4082 - val_accuracy: 0.8252\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.8084 - val_loss: 0.4082 - val_accuracy: 0.8252\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.8137 - val_loss: 0.4087 - val_accuracy: 0.8322\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8032 - val_loss: 0.4086 - val_accuracy: 0.8322\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7944 - val_loss: 0.4082 - val_accuracy: 0.8322\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8049 - val_loss: 0.4074 - val_accuracy: 0.8322\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7979 - val_loss: 0.4071 - val_accuracy: 0.8252\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\victorhu.contrera\\Documents\\pro_dexire\\pro_DEXiRE\\models\\titanic_model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\victorhu.contrera\\Documents\\pro_dexire\\pro_DEXiRE\\models\\titanic_model.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "target_dir = os.path.join(base_path, 'models')\n",
    "model.save(os.path.join(target_dir,'titanic_model.tf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, \n",
    "                             precision_recall_curve, \n",
    "                             precision_score, \n",
    "                             recall_score, \n",
    "                             f1_score, \n",
    "                             classification_report, \n",
    "                             ConfusionMatrixDisplay,\n",
    "                             confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# eval the model \n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.rint(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.89      0.83       105\n",
      "         1.0       0.80      0.65      0.72        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.77      0.77       179\n",
      "weighted avg       0.79      0.79      0.78       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x222effb2d10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cn = confusion_matrix(y_test, y_pred_classes)\n",
    "ConfusionMatrixDisplay(cn).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(base_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\victorhu.contrera\\\\Documents\\\\pro_dexire\\\\pro_DEXiRE',\n",
       " 'c:\\\\Users\\\\victorhu.contrera\\\\Anaconda3\\\\envs\\\\prodexire\\\\python310.zip',\n",
       " 'c:\\\\Users\\\\victorhu.contrera\\\\Anaconda3\\\\envs\\\\prodexire\\\\DLLs',\n",
       " 'c:\\\\Users\\\\victorhu.contrera\\\\Anaconda3\\\\envs\\\\prodexire\\\\lib',\n",
       " 'c:\\\\Users\\\\victorhu.contrera\\\\Anaconda3\\\\envs\\\\prodexire',\n",
       " '',\n",
       " 'c:\\\\Users\\\\victorhu.contrera\\\\Anaconda3\\\\envs\\\\prodexire\\\\lib\\\\site-packages',\n",
       " 'c:\\\\Users\\\\victorhu.contrera\\\\Anaconda3\\\\envs\\\\prodexire\\\\lib\\\\site-packages\\\\win32',\n",
       " 'c:\\\\Users\\\\victorhu.contrera\\\\Anaconda3\\\\envs\\\\prodexire\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'c:\\\\Users\\\\victorhu.contrera\\\\Anaconda3\\\\envs\\\\prodexire\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dexire.dexire import DEXiRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\victorhu.contrera\\Anaconda3\\envs\\prodexire\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\victorhu.contrera\\Anaconda3\\envs\\prodexire\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_dir = os.path.join(base_path, 'models')\n",
    "model = tf.keras.models.load_model(os.path.join(target_dir, 'titanic_model.tf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dexire = DEXiRE(model=model, feature_names=feature_names[:-1], class_names=['Survived', 'Not Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 947us/step\n",
      "Unique predictions: [0. 1.]\n",
      "18/18 [==============================] - 0s 824us/step\n",
      "7\n",
      "feature_7\n",
      "Symbolic expression: feature_7 <= 0.5\n",
      "4\n",
      "feature_4\n",
      "Symbolic expression: feature_4 <= 0.5\n",
      "3\n",
      "feature_3\n",
      "Symbolic expression: feature_3 <= 0.5\n",
      "Symbolic expression: feature_3 > 0.5\n",
      "0\n",
      "feature_0\n",
      "Symbolic expression: feature_0 <= 0.5\n",
      "1\n",
      "feature_1\n",
      "Symbolic expression: feature_1 <= 0.5\n",
      "Symbolic expression: feature_1 > 0.5\n",
      "Symbolic expression: feature_0 > 0.5\n",
      "Symbolic expression: feature_4 > 0.5\n",
      "5\n",
      "feature_5\n",
      "Symbolic expression: feature_5 <= 0.5\n",
      "Symbolic expression: feature_5 > 0.5\n",
      "3\n",
      "feature_3\n",
      "Symbolic expression: feature_3 <= 0.5\n",
      "Symbolic expression: feature_3 > 0.5\n",
      "0\n",
      "feature_0\n",
      "Symbolic expression: feature_0 <= 0.5\n",
      "Symbolic expression: feature_0 > 0.5\n",
      "Symbolic expression: feature_7 > 0.5\n",
      "0\n",
      "feature_0\n",
      "Symbolic expression: feature_0 <= 0.5\n",
      "Symbolic expression: feature_0 > 0.5\n",
      "0\n",
      "onehot__Sex_female\n",
      "Symbolic expression: onehot__Sex_female <= 0.5\n",
      "7\n",
      "scaler__Age\n",
      "Symbolic expression: scaler__Age <= -1.901\n",
      "Symbolic expression: scaler__Age > -1.901\n",
      "Symbolic expression: onehot__Sex_female > 0.5\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 1.388\n",
      "7\n",
      "scaler__Age\n",
      "Symbolic expression: scaler__Age <= 0.235\n",
      "8\n",
      "scaler__SibSp\n",
      "Symbolic expression: scaler__SibSp <= -0.021\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 0.147\n",
      "Symbolic expression: scaler__Parch > 0.147\n",
      "Symbolic expression: scaler__SibSp > -0.021\n",
      "Symbolic expression: scaler__Age > 0.235\n",
      "Symbolic expression: scaler__Parch > 1.388\n",
      "Unique predictions: [0. 1.]\n",
      "18/18 [==============================] - 0s 874us/step\n",
      "2\n",
      "feature_2\n",
      "Symbolic expression: feature_2 <= 0.5\n",
      "1\n",
      "feature_1\n",
      "Symbolic expression: feature_1 <= 0.5\n",
      "Symbolic expression: feature_1 > 0.5\n",
      "3\n",
      "feature_3\n",
      "Symbolic expression: feature_3 <= 0.5\n",
      "Symbolic expression: feature_3 > 0.5\n",
      "Symbolic expression: feature_2 > 0.5\n",
      "0\n",
      "feature_0\n",
      "Symbolic expression: feature_0 <= 0.5\n",
      "Symbolic expression: feature_0 > 0.5\n",
      "1\n",
      "onehot__Sex_male\n",
      "Symbolic expression: onehot__Sex_male <= 0.5\n",
      "8\n",
      "scaler__SibSp\n",
      "Symbolic expression: scaler__SibSp <= 0.886\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 3.871\n",
      "7\n",
      "scaler__Age\n",
      "Symbolic expression: scaler__Age <= -2.17\n",
      "Symbolic expression: scaler__Age > -2.17\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 1.388\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 0.147\n",
      "Symbolic expression: scaler__Parch > 0.147\n",
      "Symbolic expression: scaler__Parch > 1.388\n",
      "Symbolic expression: scaler__Parch > 3.871\n",
      "Symbolic expression: scaler__SibSp > 0.886\n",
      "Symbolic expression: onehot__Sex_male > 0.5\n",
      "total rules: [IF ((onehot__Sex_female <= 0.5) AND (scaler__Age > -1.901)) THEN Not Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__Parch <= 1.388) AND (scaler__Age <= 0.235) AND (scaler__SibSp <= -0.021) AND (scaler__Parch <= 0.147)) THEN Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__Parch <= 1.388) AND (scaler__Age > 0.235)) THEN Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__Parch > 1.388)) THEN Not Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__Parch <= 1.388) AND (scaler__Age <= 0.235) AND (scaler__SibSp > -0.021)) THEN Survived, IF ((onehot__Sex_female <= 0.5) AND (scaler__Age <= -1.901)) THEN Not Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__Parch <= 1.388) AND (scaler__Age <= 0.235) AND (scaler__SibSp <= -0.021) AND (scaler__Parch > 0.147)) THEN Survived, IF ((onehot__Sex_male > 0.5)) THEN Not Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch <= 3.871) AND (scaler__Age > -2.17) AND (scaler__Parch <= 1.388) AND (scaler__Parch <= 0.147)) THEN Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__SibSp > 0.886)) THEN Not Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch <= 3.871) AND (scaler__Age > -2.17) AND (scaler__Parch <= 1.388) AND (scaler__Parch > 0.147)) THEN Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch <= 3.871) AND (scaler__Age > -2.17) AND (scaler__Parch > 1.388)) THEN Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch > 3.871)) THEN Not Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch <= 3.871) AND (scaler__Age <= -2.17)) THEN Not Survived]\n"
     ]
    }
   ],
   "source": [
    "rule_set = dexire.extract_rules(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dexire_pro.core.dexire_pro_pipeline import DexireProPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_pipeline = DexireProPipeline(model,\n",
    "                                 feature_names=feature_names[:-1],\n",
    "                                 target_names=['Survived', 'Not Survived'],\n",
    "                                 categorical_features=categorical_features,\n",
    "                                 numerical_features=numerical_features)\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test))\n",
    "test_ds = test_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_out = [f'{feature}' for feature in feature_names[:-1] if feature.split('_')[-1] in numerical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_out = list(set(feature_names[:-1])-set(numerical_features_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pipeline = {'rule_extraction': {'tf_model_input': train_ds, \n",
    "                'X_train_xai': X_train,\n",
    "                'y_train_xai': y_train,\n",
    "                'tf_model_test_data': test_ds, \n",
    "                'X_test_xai': X_test,\n",
    "                'y_test_xai': y_test,\n",
    "                'layer_list': None,\n",
    "                'xai_feature_names': feature_names[:-1]},\n",
    "    'probabilistic_graphical_model': {\n",
    "        'numeric_features':numerical_features_out,\n",
    "        'categorical_features': categorical_out,\n",
    "        'target_col': 'y_pred'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule extraction...\n",
      "Not processing\n",
      "Extracting rules...\n",
      "18/18 [==============================] - 0s 824us/step\n",
      "Unique predictions: [0. 1.]\n",
      "18/18 [==============================] - 0s 766us/step\n",
      "7\n",
      "feature_7\n",
      "Symbolic expression: feature_7 <= 0.5\n",
      "4\n",
      "feature_4\n",
      "Symbolic expression: feature_4 <= 0.5\n",
      "3\n",
      "feature_3\n",
      "Symbolic expression: feature_3 <= 0.5\n",
      "Symbolic expression: feature_3 > 0.5\n",
      "0\n",
      "feature_0\n",
      "Symbolic expression: feature_0 <= 0.5\n",
      "1\n",
      "feature_1\n",
      "Symbolic expression: feature_1 <= 0.5\n",
      "Symbolic expression: feature_1 > 0.5\n",
      "Symbolic expression: feature_0 > 0.5\n",
      "Symbolic expression: feature_4 > 0.5\n",
      "5\n",
      "feature_5\n",
      "Symbolic expression: feature_5 <= 0.5\n",
      "Symbolic expression: feature_5 > 0.5\n",
      "3\n",
      "feature_3\n",
      "Symbolic expression: feature_3 <= 0.5\n",
      "Symbolic expression: feature_3 > 0.5\n",
      "0\n",
      "feature_0\n",
      "Symbolic expression: feature_0 <= 0.5\n",
      "Symbolic expression: feature_0 > 0.5\n",
      "Symbolic expression: feature_7 > 0.5\n",
      "0\n",
      "feature_0\n",
      "Symbolic expression: feature_0 <= 0.5\n",
      "Symbolic expression: feature_0 > 0.5\n",
      "1\n",
      "onehot__Sex_male\n",
      "Symbolic expression: onehot__Sex_male <= 0.5\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 1.388\n",
      "7\n",
      "scaler__Age\n",
      "Symbolic expression: scaler__Age <= 0.235\n",
      "8\n",
      "scaler__SibSp\n",
      "Symbolic expression: scaler__SibSp <= -0.021\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 0.147\n",
      "Symbolic expression: scaler__Parch > 0.147\n",
      "Symbolic expression: scaler__SibSp > -0.021\n",
      "Symbolic expression: scaler__Age > 0.235\n",
      "Symbolic expression: scaler__Parch > 1.388\n",
      "Symbolic expression: onehot__Sex_male > 0.5\n",
      "7\n",
      "scaler__Age\n",
      "Symbolic expression: scaler__Age <= -1.901\n",
      "Symbolic expression: scaler__Age > -1.901\n",
      "Unique predictions: [0. 1.]\n",
      "18/18 [==============================] - 0s 882us/step\n",
      "2\n",
      "feature_2\n",
      "Symbolic expression: feature_2 <= 0.5\n",
      "1\n",
      "feature_1\n",
      "Symbolic expression: feature_1 <= 0.5\n",
      "Symbolic expression: feature_1 > 0.5\n",
      "3\n",
      "feature_3\n",
      "Symbolic expression: feature_3 <= 0.5\n",
      "Symbolic expression: feature_3 > 0.5\n",
      "Symbolic expression: feature_2 > 0.5\n",
      "0\n",
      "feature_0\n",
      "Symbolic expression: feature_0 <= 0.5\n",
      "Symbolic expression: feature_0 > 0.5\n",
      "0\n",
      "onehot__Sex_female\n",
      "Symbolic expression: onehot__Sex_female <= 0.5\n",
      "Symbolic expression: onehot__Sex_female > 0.5\n",
      "8\n",
      "scaler__SibSp\n",
      "Symbolic expression: scaler__SibSp <= 0.886\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 3.871\n",
      "7\n",
      "scaler__Age\n",
      "Symbolic expression: scaler__Age <= -2.17\n",
      "Symbolic expression: scaler__Age > -2.17\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 1.388\n",
      "9\n",
      "scaler__Parch\n",
      "Symbolic expression: scaler__Parch <= 0.147\n",
      "Symbolic expression: scaler__Parch > 0.147\n",
      "Symbolic expression: scaler__Parch > 1.388\n",
      "Symbolic expression: scaler__Parch > 3.871\n",
      "Symbolic expression: scaler__SibSp > 0.886\n",
      "total rules: [IF ((onehot__Sex_male > 0.5) AND (scaler__Age > -1.901)) THEN Not Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__Parch <= 1.388) AND (scaler__Age <= 0.235) AND (scaler__SibSp <= -0.021) AND (scaler__Parch <= 0.147)) THEN Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__Parch <= 1.388) AND (scaler__Age > 0.235)) THEN Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__Parch > 1.388)) THEN Not Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__Parch <= 1.388) AND (scaler__Age <= 0.235) AND (scaler__SibSp > -0.021)) THEN Survived, IF ((onehot__Sex_male > 0.5) AND (scaler__Age <= -1.901)) THEN Not Survived, IF ((onehot__Sex_male <= 0.5) AND (scaler__Parch <= 1.388) AND (scaler__Age <= 0.235) AND (scaler__SibSp <= -0.021) AND (scaler__Parch > 0.147)) THEN Survived, IF ((onehot__Sex_female <= 0.5)) THEN Not Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch <= 3.871) AND (scaler__Age > -2.17) AND (scaler__Parch <= 1.388) AND (scaler__Parch <= 0.147)) THEN Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__SibSp > 0.886)) THEN Not Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch <= 3.871) AND (scaler__Age > -2.17) AND (scaler__Parch <= 1.388) AND (scaler__Parch > 0.147)) THEN Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch <= 3.871) AND (scaler__Age > -2.17) AND (scaler__Parch > 1.388)) THEN Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch > 3.871)) THEN Not Survived, IF ((onehot__Sex_female > 0.5) AND (scaler__SibSp <= 0.886) AND (scaler__Parch <= 3.871) AND (scaler__Age <= -2.17)) THEN Not Survived]\n",
      "Error: Mix of label input types (string and number) extracting rules\n",
      "rules extracted successfully\n",
      "Finished rule extraction step\n",
      "Probabilistic graphical model...\n",
      "[bnlearn] >Warning: Computing DAG with 12 nodes can take a very long time!\n",
      "[bnlearn] >Computing best DAG using [hc]\n",
      "[bnlearn] >Set scoring type at [bic]\n",
      "[bnlearn] >Compute structure scores for model comparison (higher is better).\n",
      "[bnlearn] >Parameter learning> Computing parameters using [bayes]\n",
      "[bnlearn] >Converting [<class 'pgmpy.base.DAG.DAG'>] to BayesianNetwork model.\n",
      "[bnlearn] >Converting adjmat to BayesianNetwork.\n",
      "[bnlearn] >CPD of onehot__Embarked_S:\n",
      "+-------------------------+-----+---------------------+\n",
      "| scaler__Pclass          | ... | scaler__Pclass(9)   |\n",
      "+-------------------------+-----+---------------------+\n",
      "| onehot__Embarked_S(0.0) | ... | 0.38928210313447925 |\n",
      "+-------------------------+-----+---------------------+\n",
      "| onehot__Embarked_S(1.0) | ... | 0.6107178968655207  |\n",
      "+-------------------------+-----+---------------------+\n",
      "[bnlearn] >CPD of onehot__Embarked_Q:\n",
      "+-------------------------+-----+-------------------------+\n",
      "| onehot__Embarked_S      | ... | onehot__Embarked_S(1.0) |\n",
      "+-------------------------+-----+-------------------------+\n",
      "| scaler__Pclass          | ... | scaler__Pclass(9)       |\n",
      "+-------------------------+-----+-------------------------+\n",
      "| onehot__Embarked_Q(0.0) | ... | 0.793046357615894       |\n",
      "+-------------------------+-----+-------------------------+\n",
      "| onehot__Embarked_Q(1.0) | ... | 0.20695364238410596     |\n",
      "+-------------------------+-----+-------------------------+\n",
      "[bnlearn] >CPD of onehot__Embarked_C:\n",
      "+-------------------------+-----+-------------------------+\n",
      "| onehot__Embarked_Q      | ... | onehot__Embarked_Q(1.0) |\n",
      "+-------------------------+-----+-------------------------+\n",
      "| onehot__Embarked_S      | ... | onehot__Embarked_S(1.0) |\n",
      "+-------------------------+-----+-------------------------+\n",
      "| onehot__Embarked_C(0.0) | ... | 0.5                     |\n",
      "+-------------------------+-----+-------------------------+\n",
      "| onehot__Embarked_C(1.0) | ... | 0.5                     |\n",
      "+-------------------------+-----+-------------------------+\n",
      "[bnlearn] >CPD of onehot__Sex_female:\n",
      "+-------------------------+-----+------------------+\n",
      "| scaler__SibSp           | ... | scaler__SibSp(9) |\n",
      "+-------------------------+-----+------------------+\n",
      "| y_pred                  | ... | y_pred(Survived) |\n",
      "+-------------------------+-----+------------------+\n",
      "| onehot__Sex_female(0.0) | ... | 0.5              |\n",
      "+-------------------------+-----+------------------+\n",
      "| onehot__Sex_female(1.0) | ... | 0.5              |\n",
      "+-------------------------+-----+------------------+\n",
      "[bnlearn] >CPD of onehot__Sex_male:\n",
      "+-----------------------+-------------------------+-------------------------+\n",
      "| onehot__Sex_female    | onehot__Sex_female(0.0) | onehot__Sex_female(1.0) |\n",
      "+-----------------------+-------------------------+-------------------------+\n",
      "| onehot__Sex_male(0.0) | 0.2853881278538813      | 0.6392496392496393      |\n",
      "+-----------------------+-------------------------+-------------------------+\n",
      "| onehot__Sex_male(1.0) | 0.7146118721461188      | 0.36075036075036077     |\n",
      "+-----------------------+-------------------------+-------------------------+\n",
      "[bnlearn] >CPD of scaler__Parch:\n",
      "+--------------------+-------------------------+-------------------------+\n",
      "| onehot__Sex_female | onehot__Sex_female(0.0) | onehot__Sex_female(1.0) |\n",
      "+--------------------+-------------------------+-------------------------+\n",
      "| scaler__Parch(0)   | 0.43770384866275275     | 0.2733457019171305      |\n",
      "+--------------------+-------------------------+-------------------------+\n",
      "| scaler__Parch(2)   | 0.1306262230919765      | 0.1535765821480107      |\n",
      "+--------------------+-------------------------+-------------------------+\n",
      "| scaler__Parch(3)   | 0.10322896281800391     | 0.15069057926200782     |\n",
      "+--------------------+-------------------------+-------------------------+\n",
      "| scaler__Parch(5)   | 0.08153946510110893     | 0.10595753452896309     |\n",
      "+--------------------+-------------------------+-------------------------+\n",
      "| scaler__Parch(6)   | 0.08268101761252446     | 0.10595753452896309     |\n",
      "+--------------------+-------------------------+-------------------------+\n",
      "| scaler__Parch(8)   | 0.08268101761252446     | 0.10595753452896309     |\n",
      "+--------------------+-------------------------+-------------------------+\n",
      "| scaler__Parch(9)   | 0.08153946510110893     | 0.10451453308596165     |\n",
      "+--------------------+-------------------------+-------------------------+\n",
      "[bnlearn] >CPD of scaler__Pclass:\n",
      "+-------------------+-----+---------------------+\n",
      "| scaler__Fare      | ... | scaler__Fare(9)     |\n",
      "+-------------------+-----+---------------------+\n",
      "| scaler__Pclass(0) | ... | 0.3425378040762656  |\n",
      "+-------------------+-----+---------------------+\n",
      "| scaler__Pclass(5) | ... | 0.32873109796186717 |\n",
      "+-------------------+-----+---------------------+\n",
      "| scaler__Pclass(9) | ... | 0.32873109796186717 |\n",
      "+-------------------+-----+---------------------+\n",
      "[bnlearn] >CPD of y_pred:\n",
      "+----------------------+-----+---------------------+\n",
      "| scaler__Pclass       | ... | scaler__Pclass(9)   |\n",
      "+----------------------+-----+---------------------+\n",
      "| y_pred(Not Survived) | ... | 0.641051567239636   |\n",
      "+----------------------+-----+---------------------+\n",
      "| y_pred(Survived)     | ... | 0.35894843276036403 |\n",
      "+----------------------+-----+---------------------+\n",
      "[bnlearn] >CPD of scaler__SibSp:\n",
      "+------------------+-----------+\n",
      "| scaler__SibSp(0) | 0.33133   |\n",
      "+------------------+-----------+\n",
      "| scaler__SibSp(2) | 0.176455  |\n",
      "+------------------+-----------+\n",
      "| scaler__SibSp(3) | 0.104434  |\n",
      "+------------------+-----------+\n",
      "| scaler__SibSp(4) | 0.0993353 |\n",
      "+------------------+-----------+\n",
      "| scaler__SibSp(5) | 0.0993353 |\n",
      "+------------------+-----------+\n",
      "| scaler__SibSp(6) | 0.0935992 |\n",
      "+------------------+-----------+\n",
      "| scaler__SibSp(9) | 0.0955112 |\n",
      "+------------------+-----------+\n",
      "[bnlearn] >CPD of scaler__Fare:\n",
      "+-----------------+-----------+\n",
      "| scaler__Fare(0) | 0.0967859 |\n",
      "+-----------------+-----------+\n",
      "| scaler__Fare(1) | 0.393153  |\n",
      "+-----------------+-----------+\n",
      "| scaler__Fare(2) | 0.128016  |\n",
      "+-----------------+-----------+\n",
      "| scaler__Fare(3) | 0.0993353 |\n",
      "+-----------------+-----------+\n",
      "| scaler__Fare(4) | 0.0955112 |\n",
      "+-----------------+-----------+\n",
      "| scaler__Fare(5) | 0.0948739 |\n",
      "+-----------------+-----------+\n",
      "| scaler__Fare(9) | 0.0923245 |\n",
      "+-----------------+-----------+\n",
      "[bnlearn] >Compute structure scores for model comparison (higher is better).\n",
      "[bnlearn] >WARNING> Skipping computing structure score for [k2].\n",
      "Pipeline execution finished successfully\n"
     ]
    }
   ],
   "source": [
    "xai_pipeline.full_pipeline(\n",
    "    train_df=pd.DataFrame(X_train, columns=feature_names[:-1]),\n",
    "    dict_steps_parameters=dict_pipeline\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prodexire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
